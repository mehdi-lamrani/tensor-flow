{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1EKkiObxkNdFL_BVP7vg01Y6DQ8ayyPJH",
      "authorship_tag": "ABX9TyNAcvnyxtLjViTldf7+MNDs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mehdi-lamrani/tensor-flow/blob/main/tensorflow_Basics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "# **Basic Tensor Operations** \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vOtdfmoMe4UL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Il s'agit d'un didacticiel d'introduction à TensorFlow qui montre comment :\n",
        "\n",
        "- Importer le package requis\n",
        "- Créer et utiliser des tenseurs\n",
        "- Utiliser l'accélération GPU\n",
        "- Démontrer tf.data.Dataset\n"
      ],
      "metadata": {
        "id": "v9-J9WW1hpbX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Importer TensorFlow**"
      ],
      "metadata": {
        "id": "KUnPQ2dEh58m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pour commencer, importez le module tensorflow . À partir de TensorFlow 2, l'exécution hâtive est activée par défaut. Cela permet une interface plus interactive pour TensorFlow, dont nous discuterons des détails beaucoup plus tard."
      ],
      "metadata": {
        "id": "FjfOjBQOiQUC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "lmQCcuAkhjvg"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Tenseurs**"
      ],
      "metadata": {
        "id": "MepfFYz-iXy0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Un tenseur est un tableau multidimensionnel. Semblables aux objets NumPy ndarray , les objets tf.Tensor ont un type de données et une forme. De plus, tf.Tensor s peut résider dans la mémoire de l'accélérateur (comme un GPU). TensorFlow offre une riche bibliothèque d'opérations ( tf.add , tf.matmul , tf.linalg.inv etc.) qui consomment et produisent des tf.Tensor s. Ces opérations convertissent automatiquement les types Python natifs, par exemple :"
      ],
      "metadata": {
        "id": "F73f4-5Xidrv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(tf.add(1, 2))\n",
        "print(tf.add([1, 2], [3, 4]))\n",
        "print(tf.square(5))\n",
        "print(tf.reduce_sum([1, 2, 3]))\n",
        "\n",
        "# Operator overloading is also supported\n",
        "print(tf.square(2) + tf.square(3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RNOktGZAe2t-",
        "outputId": "b9cfd2f4-840a-4221-9d3e-c6398ce68437"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(3, shape=(), dtype=int32)\n",
            "tf.Tensor([4 6], shape=(2,), dtype=int32)\n",
            "tf.Tensor(25, shape=(), dtype=int32)\n",
            "tf.Tensor(6, shape=(), dtype=int32)\n",
            "tf.Tensor(13, shape=(), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chaque tf.Tensor a une forme et un type de données :"
      ],
      "metadata": {
        "id": "tQm6cIhqioO-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = tf.matmul([[1]], [[2, 3]])\n",
        "print(x)\n",
        "print(x.shape)\n",
        "print(x.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bsLdVp9_ik3l",
        "outputId": "08bab31d-2c5f-4439-8ba2-026d63d3fb2e"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([[2 3]], shape=(1, 2), dtype=int32)\n",
            "(1, 2)\n",
            "<dtype: 'int32'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Les différences les plus évidentes entre les tableaux NumPy et les tf.Tensor sont :\n",
        "\n",
        "1-Les tenseurs peuvent être soutenus par une mémoire d'accélérateur (comme GPU, TPU).\n",
        "\n",
        "2-Les tenseurs sont immuables."
      ],
      "metadata": {
        "id": "qdArIVoaizgH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Compatibilité NumPy**"
      ],
      "metadata": {
        "id": "BRXwztkVjG46"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "La conversion entre un TensorFlow tf.Tensor s et un NumPy ndarray est simple :\n",
        "\n",
        "- Les opérations TensorFlow convertissent automatiquement les ndarrays NumPy en Tensors.\n",
        "- Les opérations NumPy convertissent automatiquement les Tensors en ndarrays NumPy.\n",
        "\n",
        "Les tenseurs sont explicitement convertis en ndarrays NumPy à l'aide de leur méthode .numpy() . Ces conversions sont généralement bon marché puisque le tableau et tf.Tensor partagent la représentation mémoire sous-jacente, si possible. Cependant, le partage de la représentation sous-jacente n'est pas toujours possible car le tf.Tensor peut être hébergé dans la mémoire GPU tandis que les tableaux NumPy sont toujours sauvegardés par la mémoire hôte, et la conversion implique une copie du GPU vers la mémoire hôte."
      ],
      "metadata": {
        "id": "XdexgyAcjOGn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "ndarray = np.ones([3, 3])\n",
        "\n",
        "print(\"TensorFlow operations convert numpy arrays to Tensors automatically\")\n",
        "tensor = tf.multiply(ndarray, 42)\n",
        "print(tensor)\n",
        "\n",
        "\n",
        "print(\"And NumPy operations convert Tensors to numpy arrays automatically\")\n",
        "print(np.add(tensor, 1))\n",
        "\n",
        "print(\"The .numpy() method explicitly converts a Tensor to a numpy array\")\n",
        "print(tensor.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9JPo46EwjN06",
        "outputId": "b2af9027-fc77-4417-82e2-9835f1c0bc8e"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow operations convert numpy arrays to Tensors automatically\n",
            "tf.Tensor(\n",
            "[[42. 42. 42.]\n",
            " [42. 42. 42.]\n",
            " [42. 42. 42.]], shape=(3, 3), dtype=float64)\n",
            "And NumPy operations convert Tensors to numpy arrays automatically\n",
            "[[43. 43. 43.]\n",
            " [43. 43. 43.]\n",
            " [43. 43. 43.]]\n",
            "The .numpy() method explicitly converts a Tensor to a numpy array\n",
            "[[42. 42. 42.]\n",
            " [42. 42. 42.]\n",
            " [42. 42. 42.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Accélération GPU**"
      ],
      "metadata": {
        "id": "CGtoaw-QkNTb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "De nombreuses opérations TensorFlow sont accélérées à l'aide du GPU pour le calcul. Sans aucune annotation, TensorFlow décide automatiquement d'utiliser le GPU ou le CPU pour une opération, en copiant le tenseur entre la mémoire CPU et GPU, si nécessaire. Les tenseurs produits par une opération sont généralement sauvegardés par la mémoire de l'appareil sur lequel l'opération est exécutée, par exemple :"
      ],
      "metadata": {
        "id": "DfGFEcaKkPLi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = tf.random.uniform([3, 3])\n",
        "\n",
        "print(\"Is there a GPU available: \"),\n",
        "print(tf.config.list_physical_devices(\"GPU\"))\n",
        "\n",
        "print(\"Is the Tensor on GPU #0:  \"),\n",
        "print(x.device.endswith('GPU:0'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0xCRznMti6lN",
        "outputId": "4cdcdf02-1e96-49fc-b146-d72dee029beb"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Is there a GPU available: \n",
            "[]\n",
            "Is the Tensor on GPU #0:  \n",
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Noms de périphérique**"
      ],
      "metadata": {
        "id": "PJlkr7JSkpkE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "La propriété Tensor.device fournit un nom de chaîne complet du périphérique hébergeant le contenu du tenseur. Ce nom encode de nombreux détails, tels qu'un identifiant de l'adresse réseau de l'hôte sur lequel ce programme s'exécute et le périphérique au sein de cet hôte. Ceci est nécessaire pour l'exécution distribuée d'un programme TensorFlow. La chaîne se termine par GPU:<N> si le tenseur est placé sur le N -ième GPU sur l'hôte."
      ],
      "metadata": {
        "id": "lWazDggik1aD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Placement explicite de l'appareil**"
      ],
      "metadata": {
        "id": "P6iIWfVbk4n6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dans TensorFlow, le placement fait référence à la façon dont les opérations individuelles sont attribuées (placées sur) un appareil pour exécution. Comme mentionné, lorsqu'aucune instruction explicite n'est fournie, TensorFlow décide automatiquement quel appareil exécuter une opération et copie les tenseurs sur cet appareil, si nécessaire. Cependant, les opérations TensorFlow peuvent être explicitement placées sur des appareils spécifiques à l'aide du gestionnaire de contexte tf.device , par exemple :"
      ],
      "metadata": {
        "id": "CimsVkHEk8i1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "def time_matmul(x):\n",
        "  start = time.time()\n",
        "  for loop in range(10):\n",
        "    tf.matmul(x, x)\n",
        "\n",
        "  result = time.time()-start\n",
        "\n",
        "  print(\"10 loops: {:0.2f}ms\".format(1000*result))\n",
        "\n",
        "# Force execution on CPU\n",
        "print(\"On CPU:\")\n",
        "with tf.device(\"CPU:0\"):\n",
        "  x = tf.random.uniform([1000, 1000])\n",
        "  assert x.device.endswith(\"CPU:0\")\n",
        "  time_matmul(x)\n",
        "\n",
        "# Force execution on GPU #0 if available\n",
        "if tf.config.list_physical_devices(\"GPU\"):\n",
        "  print(\"On GPU:\")\n",
        "  with tf.device(\"GPU:0\"): # Or GPU:1 for the 2nd GPU, GPU:2 for the 3rd etc.\n",
        "    x = tf.random.uniform([1000, 1000])\n",
        "    assert x.device.endswith(\"GPU:0\")\n",
        "    time_matmul(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "poAhIVPzk_YU",
        "outputId": "aba86025-d391-43d6-83e5-e2be073fdacf"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "On CPU:\n",
            "10 loops: 327.13ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Jeux de données**"
      ],
      "metadata": {
        "id": "IzGcqL9mlKlE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cette section utilise l' API tf.data.Dataset pour créer un pipeline permettant d'alimenter en données votre modèle. L'API tf.data.Dataset est utilisée pour créer des pipelines d'entrée complexes et performants à partir de pièces simples et réutilisables qui alimenteront les boucles d'entraînement ou d'évaluation de votre modèle."
      ],
      "metadata": {
        "id": "GhPcp3j9lMGh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Créer un jeu de Dataset source**"
      ],
      "metadata": {
        "id": "aE9SOQgglTMd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Créez un jeu de données source à l'aide de l'une des fonctions d'usine telles que Dataset.from_tensors , Dataset.from_tensor_slices ou à l'aide d'objets qui lisent à partir de fichiers tels que TextLineDataset ou TFRecordDataset . "
      ],
      "metadata": {
        "id": "AdeOkwChlft4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ds_tensors = tf.data.Dataset.from_tensor_slices([1, 2, 3, 4, 5, 6])\n",
        "\n",
        "# Create a CSV file\n",
        "import tempfile\n",
        "_, filename = tempfile.mkstemp()\n",
        "\n",
        "with open(filename, 'w') as f:\n",
        "  f.write(\"\"\"Line 1\n",
        "Line 2\n",
        "Line 3\n",
        "  \"\"\")\n",
        "\n",
        "ds_file = tf.data.TextLineDataset(filename)"
      ],
      "metadata": {
        "id": "hbW9z0WVlnAO"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Appliquer des transformations**"
      ],
      "metadata": {
        "id": "ktyhqdoTlqmQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Utilisez les fonctions de transformation telles que map , batch et shuffle pour appliquer des transformations aux enregistrements de l'ensemble de données.\n"
      ],
      "metadata": {
        "id": "qHC-DYmglk3A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ds_tensors = ds_tensors.map(tf.square).shuffle(2).batch(2)\n",
        "\n",
        "ds_file = ds_file.batch(2)"
      ],
      "metadata": {
        "id": "EdZQWj0kmCmu"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Répéter"
      ],
      "metadata": {
        "id": "XChrNUnel5Lu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Les objets tf.data.Dataset prennent en charge l'itération pour parcourir les enregistrements :"
      ],
      "metadata": {
        "id": "CeyWZNH9mOlM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Elements of ds_tensors:')\n",
        "for x in ds_tensors:\n",
        "  print(x)\n",
        "\n",
        "print('\\nElements in ds_file:')\n",
        "for x in ds_file:\n",
        "  print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TLu94sSXmIvo",
        "outputId": "b123bb4d-8a12-4925-ff9c-02cc3a7f7f45"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elements of ds_tensors:\n",
            "tf.Tensor([1 4], shape=(2,), dtype=int32)\n",
            "tf.Tensor([ 9 25], shape=(2,), dtype=int32)\n",
            "tf.Tensor([16 36], shape=(2,), dtype=int32)\n",
            "\n",
            "Elements in ds_file:\n",
            "tf.Tensor([b'Line 1' b'Line 2'], shape=(2,), dtype=string)\n",
            "tf.Tensor([b'Line 3' b'  '], shape=(2,), dtype=string)\n"
          ]
        }
      ]
    }
  ]
}